<?xml version="1.0" encoding="UTF-8"?>
<configuration scan="true" scanPeriod="60 seconds" debug="false">
	<!--scan:当此属性设置为true时，配置文件如果发生改变，将会被重新加载，默认值为true。-->
	<!--scanPeriod:设置监测配置文件是否有修改的时间间隔，如果没有给出时间单位，默认单位是毫秒。当scan为true时，此属性生效。默认的时间间隔为1分钟。-->
	<!--debug:当此属性设置为true时，将打印出logback内部日志信息，实时查看logback运行状态。默认值为false。-->
	<contextName>${APP_NAME}</contextName>

	<!-- Context listeners -->
	<contextListener class="com.taotao.cloud.logger.listener.TtlMDCAdapterListener"/>
	<!--	<contextListener class="com.yomahub.tlog.core.enhance.logback.TLogLogbackTTLMdcListener"/>-->

	<property name="LOG_PATH" value="${user.home}"/>
	<property name="OS_NAME" value="${os.name}"/>
	<property name="OS_VERSION" value="${os.version}"/>
	<property name="USER_TIMEZONE" value="${user.timezone}"/>
	<property name="JAVA_VERSION" value="${java.version}"/>
	<property name="CURRENT_DATE" value="%d{yyyy-MM-dd}"/>

	<springProperty name="TAOTAO_CLOUD_VERSION" scope="context" source="taotaoCloudVersion"
		defaultValue="--"/>
	<springProperty name="APP_NAME" scope="context" source="spring.application.name"
		defaultValue="--"/>
	<springProperty name="SPRING_PROFILES_ACTIVE" scope="context" source="spring.profiles.active"/>
	<springProperty name="LOG_FILE" scope="context" source="logging.file.path"
		defaultValue="${LOG_PATH}/logs/${APP_NAME}"/>
	<springProperty name="LOG_MAX_FILE_SIZE" scope="context"
		source="logging.logback.rollingpolicy.max-file-size"
		defaultValue="2GB"/>
	<springProperty name="CLEAN_HISTORY_ON_START" scope="context"
		source="logging.logback.rollingpolicy.clean-history-on-start"
		defaultValue="true"/>
	<springProperty name="TOTAL_SIZE_CAP" scope="context"
		source="logging.logback.rollingpolicy.total-size-cap"
		defaultValue="7GB"/>
	<springProperty name="LOG_FILE_MAX_DAY" scope="context"
		source="logging.logback.rollingpolicy.max-history"
		defaultValue="30"/>
	<springProperty name="SERVER_IP" scope="context" source="spring.cloud.client.ip-address"
		defaultValue="0.0.0.0"/>
	<springProperty name="SERVER_PORT" scope="context" source="server.port"
		defaultValue="--"/>
	<springProperty name="BOOTSTRAP_SERVERS" scope="context" source="spring.kafka.bootstrap-servers"
		defaultValue="192.168.10.210:9092"/>
	<springProperty name="LOGSTASH_DESTINATION" scope="context"
		source="logging.extend.logstash-appender.destination"
		defaultValue="192.168.10.210:4560"/>

	<!--https://logback.qos.ch/manual/layouts.html-->

	<!-- LOG_LEVEL_PATTERN	see ch.qos.logback.classic.PatternLayout-->
	<!--<springProperty name="CONSOLE_LOG_PATTERN" source="logging.pattern.console"-->
	<!--	defaultValue="[%clr(${APP_NAME}){green}:%clr(${SERVER_IP}){green}:%clr(${SERVER_PORT}){green}] %clr(%d{yyyy-MM-dd HH:mm:ss.SSS}){green} %clr([%thread]){red} %clr([${SPRING_PROFILES_ACTIVE:-}]){green} %clr([%level]){blue} %clr([${PID}]){magenta} %clr([${OS_NAME:-}:${OS_VERSION:-}]){yellow} %clr([${USER_TIMEZONE:-}]){yellow} %clr([${JAVA_VERSION:-}]){yellow} %clr(Version:[${TAOTAO_CLOUD_VERSION}]){green} %clr(TraceId:[%X{taotao-cloud-trace-id:-}]){orange} %clr(TenantId:[%X{taotao-cloud-tenant-id:-}]){cyan} %clr(RequestVersion:[%X{taotao-cloud-request-version:-}]){yellow} %clr(ZipkinTraceId:[%X{X-B3-TraceId:-}:%X{X-B3-SpanId:-}]){magenta} %clr([%tid]){magenta} %clr(%logger{360}){cyan} %clr([%F:%M:%L]){orange} %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%wEx}"/>-->
	<springProperty name="CONSOLE_LOG_PATTERN" source="logging.pattern.console"
		defaultValue="%clr(%d{yyyy-MM-dd HH:mm:ss.SSS}){green} %clr(%level){blue} %clr(${PID}){magenta} %clr([${APP_NAME}:${SERVER_IP}:${SERVER_PORT}]){green} %clr([${TAOTAO_CLOUD_VERSION}]){green} %clr([%thread]){red} %clr([${SPRING_PROFILES_ACTIVE:--}]){faint} %clr([${OS_NAME:-}:${OS_VERSION:-}:${USER_TIMEZONE:-}:${JAVA_VERSION:-}]){yellow} %clr(Tlog:[%X{tl}]){cyan} %clr(TraceId:[%X{taotao-cloud-trace-id:-}]){orange} %clr(TenantId:[%X{taotao-cloud-tenant-id:-}]){cyan} %clr(RequestVersion:[%X{taotao-cloud-request-version:-}]){yellow} %clr(ZipkinTraceId:[%X{X-B3-TraceId:-}:%X{X-B3-SpanId:-}]){magenta} %clr([%tid]){magenta} %clr(%class{360}:%M:%L){cyan} : %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%wEx}"/>

	<!--
	   日志输出格式：
		   %d表示日期时间，
		   %thread表示线程名，
		   %-5level：级别从左显示5个字符宽度
		   %logger{50} 表示logger名字最长50个字符，否则按照句点分割。
		   %msg：日志消息，
		   %n是换行符
		   %-15.15():如果记录的线程字符长度小于15(第一个)则用空格在右侧补齐,如果字符长度大于15(第二个),则从开头开始截断多余的字符
		   %-50.50()：如果记录的logger字符长度小于50(第一个)则用空格在右侧补齐,如果字符长度大于50(第二个),则从开头开始截断多余的字符
		   %highlight()：颜色，info为蓝色，warn为浅红，error为加粗红，debug为黑色
		   %boldMagenta:粗红
		   %magenta:洋红
		   $cyan:青色
		   %white:白色
	   -->
	<!--<springProperty name="CONSOLE_LOG_PATTERN_NO_COLOR" source="logging.pattern.console.no.color"-->
	<!--	defaultValue="[${APP_NAME}:${SERVER_IP}:${SERVER_PORT}] %d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] [${SPRING_PROFILES_ACTIVE:-}] [%level] [${PID}] [${OS_NAME:-}:${OS_VERSION:-}] [${USER_TIMEZONE:-}] [${JAVA_VERSION:-}] Version:[${TAOTAO_CLOUD_VERSION}] TraceId:[%X{taotao-cloud-trace-id:-}] TenantId:[%X{taotao-cloud-tenant-id:-}] RequestVersion:[%X{taotao-cloud-request-version:-}] ZipkinTraceId:[%X{X-B3-TraceId:-}:%X{X-B3-SpanId:-}] [%tid] %logger{360} %clr([%F:%M:%L]){orange} %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%wEx}"/>-->
	<springProperty name="CONSOLE_LOG_PATTERN_NO_COLOR" source="logging.pattern.console.no.color"
		defaultValue="%d{yyyy-MM-dd HH:mm:ss.SSS} %level ${PID} [${APP_NAME}:${SERVER_IP}:${SERVER_PORT}] [${TAOTAO_CLOUD_VERSION}] [%thread] [${SPRING_PROFILES_ACTIVE:--}] [${OS_NAME:-}:${OS_VERSION:-}:${USER_TIMEZONE:-}:${JAVA_VERSION:-}] Tlog:[%X{tl}] TraceId:[%X{taotao-cloud-trace-id:-}] TenantId:[%X{taotao-cloud-tenant-id:-}] RequestVersion:[%X{taotao-cloud-request-version:-}] ZipkinTraceId:[%X{X-B3-TraceId:-}:%X{X-B3-SpanId:-}] [%tid] %class{360}:%M:%L : %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%wEx}"/>

	<conversionRule conversionWord="clr"
		converterClass="org.springframework.boot.logging.logback.ColorConverter"/>
	<conversionRule conversionWord="wex"
		converterClass="org.springframework.boot.logging.logback.WhitespaceThrowableProxyConverter"/>
	<conversionRule conversionWord="wEx"
		converterClass="org.springframework.boot.logging.logback.ExtendedWhitespaceThrowableProxyConverter"/>
	<conversionRule conversionWord="wEx2"
		converterClass="com.taotao.cloud.logger.logback.ExtendedWhitespaceThrowableProxyConverter"/>

	<include resource="logback/console-appender.xml"/>
	<include resource="logback/file-appender.xml"/>
	<include resource="logback/kafka-appender.xml"/>
	<!--	<include resource="logback/loki-appender.xml"/>-->
	<!--	<include resource="logback/graylog-appender.xml"/>-->
	<!--	<include resource="logback/logstash-appender.xml"/>-->
	<!--		<include resource="logback/db-appender.xml"/>-->

	<!--
        <logger>用来设置某一个包或者具体的某一个类的日志打印级别、
        以及指定<appender>。<logger>仅有一个name属性，
        一个可选的level和一个可选的addtivity属性。
        name:用来指定受此logger约束的某一个包或者具体的某一个类。
        level:用来设置打印级别，大小写无关：TRACE, DEBUG, INFO, WARN, ERROR, ALL 和 OFF，
              还有一个特俗值INHERITED或者同义词NULL，代表强制执行上级的级别。
              如果未设置此属性，那么当前logger将会继承上级的级别。
        addtivity:是否向上级logger传递打印信息。默认是true。
        <logger name="org.springframework.web" level="info"/>
        <logger name="org.springframework.scheduling.annotation.ScheduledAnnotationBeanPostProcessor" level="INFO"/>
    -->

	<!--为某个包单独配置logger
    比如定时任务，写代码的包名为：net.add1s.slf4j-logback
    步骤如下：
    1、定义一个appender，取名为task（随意，只要下面logger引用就行了）
    appender的配置按照需要即可
    2、定义一个logger:
    <logger name="net.add1s.slf4j-logback" level="DEBUG" additivity="false">
      <appender-ref ref="task" />
    </logger>
    addtivity:是否向上级loger传递打印信息。默认是true。
    注意：additivity必须设置为false，这样只会交给task这个appender，否则其他appender也会打印net.add1s.slf4j-logback里的log信息。
    3、这样，在net.add1s.slf4j-logback的logger就会是上面定义的logger了。
    private static Logger logger = LoggerFactory.getLogger(Class1.class);
    -->

	<!--<logger name="org.springframework.cloud.openfeign" level="DEBUG"/>-->
	<!--<logger name="org.apache.kafka" level="OFF"/>-->
	<!--<logger name="org.apache.zookeeper.ZooKeeper" level="ERROR"/>-->

	<!-- show parameters for hibernate sql 专为 Hibernate 定制 -->
	<logger name="org.hibernate.type.descriptor.sql.BasicBinder" level="TRACE"/>
	<logger name="org.hibernate.type.descriptor.sql.BasicExtractor" level="DEBUG"/>
	<logger name="org.hibernate.SQL" level="DEBUG"/>
	<logger name="org.hibernate.engine.QueryParameters" level="DEBUG"/>
	<logger name="org.hibernate.engine.query.HQLQueryPlan" level="DEBUG"/>

	<!--myibatis log configure-->
	<logger name="com.apache.ibatis" level="TRACE"/>
	<logger name="java.sql.Connection" level="DEBUG"/>
	<logger name="java.sql.Statement" level="DEBUG"/>
	<logger name="java.sql.PreparedStatement" level="DEBUG"/>
	<logger name="kafka.server.KafkaConfig" level="INFO"/>
	<logger name="org.I0Itec.zkclient" level="INFO"/>
	<logger name="kafka.admin.AdminClient.AdminConfig" level="INFO"/>

	<!-- 输出SQL到控制台和文件-->
	<logger name="org.hibernate.SQL" additivity="false">
		<level value="DEBUG"/>
		<appender-ref ref="FILE_SQL_ASYNC_APPENDER"/>
	</logger>

	<!-- 输出SQL的参数到控制台和文件-->
	<logger name="org.hibernate.type.descriptor.sql.BasicBinder" additivity="false" level="TRACE">
		<level value="TRACE"/>
		<appender-ref ref="FILE_SQL_ASYNC_APPENDER"/>
	</logger>

	<!-- 日志输出级别，OFF level > FATAL > ERROR > WARN > INFO > DEBUG > ALL level -->
	<!--	<root level="INFO">-->
	<!--		<appender-ref ref="CONSOLE_ASYNC_APPENDER"/>-->
	<!--		<appender-ref ref="FILE_ALL_ASYNC_APPENDER"/>-->
	<!--		<appender-ref ref="FILE_WARN_ASYNC_APPENDER"/>-->
	<!--		<appender-ref ref="FILE_ERROR_ASYNC_APPENDER"/>-->
	<!--		<appender-ref ref="FILE_DEBUG_ASYNC_APPENDER"/>-->
	<!--		<appender-ref ref="KAFKA_ASYNC_APPENDER"/>-->
	<!--		<appender-ref ref="GELF_ASYNC_APPENDER"/>-->
	<!--		<appender-ref ref="LOKI_ASYNC_APPENDER"/>-->
	<!--		&lt;!&ndash;<appender-ref ref="LOGSTASH_ASYNC_APPENDER"/>&ndash;&gt;-->
	<!--	</root>-->

	<springProfile name="dev">
		<root level="INFO">
			<appender-ref ref="CONSOLE_ASYNC_APPENDER"/>
			<appender-ref ref="FILE_ALL_ASYNC_APPENDER"/>
			<appender-ref ref="FILE_WARN_ASYNC_APPENDER"/>
			<appender-ref ref="FILE_ERROR_ASYNC_APPENDER"/>
			<appender-ref ref="FILE_DEBUG_ASYNC_APPENDER"/>
			<appender-ref ref="KAFKA_ASYNC_APPENDER"/>
			<!--			<appender-ref ref="GELF_ASYNC_APPENDER"/>-->
			<!--			<appender-ref ref="LOKI_ASYNC_APPENDER"/>-->
			<!--			<appender-ref ref="LOGSTASH_ASYNC_APPENDER"/>-->
		</root>
	</springProfile>

	<springProfile name="test">
		<root level="INFO">
			<appender-ref ref="CONSOLE_ASYNC_APPENDER"/>
			<appender-ref ref="FILE_ALL_ASYNC_APPENDER"/>
			<appender-ref ref="FILE_WARN_ASYNC_APPENDER"/>
			<appender-ref ref="FILE_ERROR_ASYNC_APPENDER"/>
			<!--<appender-ref ref="KAFKA_APPENDER"/>-->
			<!--<appender-ref ref="LOGSTASH_ASYNC_APPENDER"/>-->
		</root>
	</springProfile>

	<springProfile name="pre">
		<root level="INFO">
			<appender-ref ref="CONSOLE_ASYNC_APPENDER"/>
			<appender-ref ref="FILE_ALL_ASYNC_APPENDER"/>
			<appender-ref ref="FILE_WARN_ASYNC_APPENDER"/>
			<appender-ref ref="FILE_ERROR_ASYNC_APPENDER"/>
			<!--<appender-ref ref="KAFKA_APPENDER"/>-->
			<!--<appender-ref ref="LOGSTASH_ASYNC_APPENDER"/>-->
		</root>
	</springProfile>

	<!-- 生产环境,多个使用逗号隔开,生产环境输出ERROR级别日志,只以文件形式输出-->
	<springProfile name="prod">
		<logger name="org.hibernate.type.descriptor.sql.BasicBinder" additivity="false"
			level="TRACE">
			<level value="TRACE"/>
			<appender-ref ref="FILE_SQL_ASYNC_APPENDER"/>
		</logger>

		<root level="ERROR">
			<appender-ref ref="CONSOLE_ASYNC_APPENDER"/>
			<appender-ref ref="FILE_ALL_ASYNC_APPENDER"/>
			<appender-ref ref="FILE_WARN_ASYNC_APPENDER"/>
			<appender-ref ref="FILE_ERROR_ASYNC_APPENDER"/>
			<!--<appender-ref ref="KAFKA_APPENDER"/>-->
			<!--<appender-ref ref="LOGSTASH_ASYNC_APPENDER"/>-->
		</root>
	</springProfile>
</configuration>
