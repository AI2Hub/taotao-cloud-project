阶段大纲:
    一. 爬虫
        1. 基本操作
            - 登录任意网站(伪造浏览器的任何行为)
        2. 性能相关
            - 并发方案: 
                - 异步IO: gevent/Twisted/asyncio/aiohttp
                - 自定义异步IO模块
                - IO多路复用:select
        3. Scrapy框架
            介绍:异步IO:Twisted
            - 基于Scrapy源码自定义爬虫框架
            - 使用Scrapy
            
    二. Tornado框架(异步非阻塞)
        1. Tornado的基本使用
            - 小示例
            - 自定义组件
        2. Tornado源码剖析
            
        3. 自定义异步非阻塞框架 select实现
        
        
1. 爬虫基本操作
    a. 爬虫
          - 定向
          - 非定向
    
    b. 
        需求一:
            下载页面:
                http://www.autohome.com.cn/news/
                
            筛选:
                正则表达式
        
            ========== 开源模块 ==========
            
            1. requests
                pip3 install requests
                
                response = requests.get('http://www.autohome.com.cn/news/')
                response.text
                
                
                总结:
                
                response = requests.get('URL')
                response.text
                response.content
                response.encoding
                response.aparent_encoding
                response.status_code
                response.cookies.get_dict()
                
                
                requests.get('http://www.autohome.com.cn/news/',cookie={'xx':'xxx'})
                
            2. beautisoup模块
                pip3 install beautifulsoup4
                
                from bs4 import BeautiSoup
                soup = BeautiSoup(response.text,features='html.parser')
                target = soup.find(id='auto-channel-lazyload-article')
                print(target)
            
                总结:
                    soup = beautifulsoup('<html>...</html>',features='html.parser')
                    v1 = soup.find('div')
                    v1 = soup.find(id='i1')
                    v1 = soup.find('div',id='i1')
                    
                    v2 = soup.find_all('div')
                    v2 = soup.find_all(id='i1')
                    v2 = soup.find_all('div',id='i1')
            
                    obj = v1
                    obj = v2[0]
                    
                    obj.text
                    obj.attrs
    
    
        需求二:
            通过程序自动登录github
            
            post_dict = {
                "phone": '111111111',
                'password': 'xxx',
                'oneMonth': 1
            }
            response = requests.post(
                url="http://dig.chouti.com/login",
                data = post_dict
            )
            
            print(response.text)
            cookie_dict = response.cookies.get_dict()
    
    
    c. 模块详细使用
        requests
        
        - 方法关系
            requests.get(.....)
            requests.post(.....)
            requests.put(.....)
            requests.delete(.....)
            ...
            
            requests.request('POST'...)
        - 参数
            request.request
            - method:  提交方式
            - url:     提交地址
            - params:  在URL中传递的参数,GET 
                requests.request(
                    method='GET',
                    url= 'http://www.oldboyedu.com',
                    params = {'k1':'v1','k2':'v2'}
                )
                # http://www.oldboyedu.com?k1=v1&k2=v2
            - data:    在请求体里传递的数据
            
                requests.request(
                    method='POST',
                    url= 'http://www.oldboyedu.com',
                    params = {'k1':'v1','k2':'v2'},
                    data = {'use':'alex','pwd': '123','x':[11,2,3]}
                )
                
                请求头:
                    content-type: application/url-form-encod.....
                    
                请求体:
                    use=alex&pwd=123
                
                
            - json   在请求体里传递的数据
                requests.request(
                    method='POST',
                    url= 'http://www.oldboyedu.com',
                    params = {'k1':'v1','k2':'v2'},
                    json = {'use':'alex','pwd': '123'}
                )
                请求头:
                    content-type: application/json
                    
                请求体:
                    "{'use':'alex','pwd': '123'}"
                
                PS: 字典中嵌套字典时
                
            - headers   请求头
            
                requests.request(
                    method='POST',
                    url= 'http://www.oldboyedu.com',
                    params = {'k1':'v1','k2':'v2'},
                    json = {'use':'alex','pwd': '123'},
                    headers={
                        'Referer': 'http://dig.chouti.com/',
                        'User-Agent': "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36"
                    }
                )
             - cookies  Cookies
        
            
             
             - files    上传文件
             
             - auth      基本认知(headers中加入加密的用户名和密码)
             
             - timeout  请求和响应的超市时间
             
             - allow_redirects  是否允许重定向
             
             - proxies  代理
             
             - verify   是否忽略证书
             
             - cert      证书文件
             
             - stream   村长下大片
             
        - session: 用于保存客户端历史访问信息
             
             
             
             
             
             
        
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    